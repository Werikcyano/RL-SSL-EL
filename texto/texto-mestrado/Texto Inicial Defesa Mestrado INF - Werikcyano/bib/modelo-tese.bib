%% NOTE: \LaTeX's comment character `%' is not a comment character in
%% the database files.  \BibTeX allows in the database files any
%% comment that's not within an entry.
%%
%% Repositorio de arquivos .bib disponiveis on-line:
%% http://liinwww.ira.uka.de/bibliography/index.html
%% http://www.math.utah.edu/~beebe/bibliographies.html
%%
%% Se voc� tiver problemas com acentos nas entradas do BibTeX, coloque-os
%% entre { e }, como em Jo{�}o ou ainda Jo{\~a}o.

%---------------------------------------------------------
% A A A
%---------------------------------------------------------



@book{monte_carlo_statistical_methods,
  title={Monte Carlo statistical methods},
  author={Robert, Christian P and Casella, George and Casella, George},
  volume={2},
  year={1999},
  publisher={Springer}
}


@book{introducao_modelos_probabilisticos,
  title={Introduction to probability models},
  author={Ross, Sheldon M},
  year={2014},
  publisher={Academic press}
}

@article{robocin,
  author       = {Hansenclever F. Bassani and
                  Renie A. Delgado and
                  Jos{\'{e}} Nilton de O. Lima Junior and
                  Heitor R. Medeiros and
                  Pedro H. M. Braga and
                  Alain Tapp},
  title        = {Learning to Play Soccer by Reinforcement and Applying Sim-to-Real
                  to Compete in the Real World},
  journal      = {CoRR},
  volume       = {abs/2003.11102},
  year         = {2020},
  url          = {https://arxiv.org/abs/2003.11102},
  eprinttype    = {arXiv},
  eprint       = {2003.11102},
  timestamp    = {Wed, 16 Sep 2020 09:49:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2003-11102.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{mcmc,
  title={Markov chain Monte Carlo: stochastic simulation for Bayesian inference},
  author={Gamerman, Dani and Lopes, Hedibert F},
  year={2006},
  publisher={CRC press}
}

@ARTICLE{bruno_brandao,
  author={Brandão, Bruno and De Lima, Telma Woerle and Soares, Anderson and Melo, Luckeciano and Maximo, Marcos R. O. A.},
  journal={IEEE Access}, 
  title={Multiagent Reinforcement Learning for Strategic Decision Making and Control in Robotic Soccer Through Self-Play}, 
  year={2022},
  volume={10},
  number={},
  pages={72628-72642},
  doi={10.1109/ACCESS.2022.3189021}}



@book{sutton,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}


@article{pequi_tdp,
  title={Pequi Mec{\^a}nico IEEE VSS Soccer Team-CBR 2017},
  author={Gomes, Adriel O and Paula, Alisson R and Martins, Bruno BS and Oliveira, Bryan LM and Silva, Daniel F and Quijano, Eduardo HD and Assis, Lucas S and Dias, Nigel JB and Mortosa, Ot{\'a}vio S and Alves, Pedro SR and others}
}

@misc{cbr_site,
    title = {Latin American and Brazilian Robotics Competition},
    year = {2023},
    url = {https://www.cbrobotica.org/}
}

@misc{regras_ssl_el_2024,
    title = {Regras para competição Robocup Small Size League Entry-Level (SSL-EL) },
    year = {2024},
    url = {https://cbr.robocup.org.br/wp-content/uploads/2024/08/sslrules.pdf}
}


@inproceedings{robocup,
    author = {Fahami, M. A. and Roshanzamir, M. and Izadi, N. H.},
    title = {A Reinforcement Learning Approach to Score Goals in RoboCup 3D Soccer Simulation for NAO Humanoid Robot},
    booktitle = {2017 7th International Conference on Computer and Knowledge Engineering (ICCKE)},
    pages = {450--454},
    year = {2017},
    month = {2},
    day = {26}
}


@article{sequential_monte_carlo,
    author = {Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
    title = "{Sequential Monte Carlo Samplers}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {68},
    number = {3},
    pages = {411-436},
    year = {2006},
    month = {05},
    abstract = "{We propose a methodology to sample sequentially from a sequence of probability distributions that are defined on a common space, each distribution being known up to a normalizing constant. These probability distributions are approximated by a cloud of weighted random samples which are propagated over time by using sequential Monte Carlo methods. This methodology allows us to derive simple algorithms to make parallel Markov chain Monte Carlo algorithms interact to perform global optimization and sequential Bayesian estimation and to compute ratios of normalizing constants. We illustrate these algorithms for various integration tasks arising in the context of Bayesian inference.}",
    issn = {1369-7412},
    doi = {10.1111/j.1467-9868.2006.00553.x},
    url = {https://doi.org/10.1111/j.1467-9868.2006.00553.x},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/68/3/411/49795343/jrsssb\_68\_3\_411.pdf},
}

@article{markov_simple,
    author = {van Ravenzwaaij, Don and Cassey, Pete and Brown, Scott D.},
    title = {A simple introduction to Markov Chain Monte–Carlo sampling},
    journal = {Psychonomic Bulletin \& Review},
    volume = {25},
    number = {1},
    pages = {143--154},
    year = {2018},
    month = {2},
    doi = {10.3758/s13423-016-1015-8},
    url = {https://doi.org/10.3758/s13423-016-1015-8},
    issn = {1531-5320}
}

@book{eficiencia_amostragem,
    author    = {Max Lapan},
    title     = {Deep Reinforcement Learning Hands-On: Apply modern RL methods, with deep Q-networks, value iteration, policy gradients, TRPO, AlphaGo Zero and more},
    year      = {2018},
    publisher = {Packt Publishing Ltd}
}

@inproceedings{Job2023TelemetriaAU,
  title={Telemetria Adaptativa Usando Aprendizado por Reforço Profundo em Redes Definidas por Software},
  author={Debora H. Job and Sidney C. de Lucena and Pedro Nuno Moura},
  booktitle={Brazilian Symposium on Computer Networks and Distributed Systems},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259756761}
}

@article{Kinoshita2022AprendizadoPR,
  title={Aprendizado por Reforço Profundo com Redes Recorrentes Aplicado {\`a} Negociaç{\~a}o do Minicontrato Futuro de D{\'o}lar},
  author={Jonathan Kenji Kinoshita and Douglas De Rizzo Meneghetti and Reinaldo Augusto da Costa Bianchi},
  journal={Anais do I Brazilian Workshop on Artificial Intelligence in Finance (BWAIF 2022)},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:250578214}
}

@article{Jesus2023AprendizadoPR,
  title={Aprendizado por Reforço Profundo para Navegaç{\~a}o Sem Mapa de um Ve{\'i}culo H{\'i}brido A{\'e}reo-Aqu{\'a}tico usando Imagens},
  author={Junior D. Jesus and Paulo Lilles Jorge Drews-Jr and Rodrigo da Silva Guerra},
  journal={Anais Estendidos do XV Simp{\'o}sio Brasileiro de Rob{\'o}tica e XX Simp{\'o}sio Latino-Americano de Rob{\'o}tica (SBR/LARS Estendido 2023)},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:267249421}
}

@article{Grando2021AprendizadoPR,
  title={Aprendizado por Reforço Profundo para Navegaç{\~a}o sem Mapa de um Ve{\'i}culo H{\'i}brido A{\'e}reo-Aqu{\'a}tico},
  author={Ricardo B. Grando and Paulo Lilles Jorge Drews-Jr},
  journal={Anais Estendidos do XIII Simp{\'o}sio Brasileiro de Rob{\'o}tica e XVIII Simp{\'o}sio Latino Americano de Rob{\'o}tica (SBR/LARS Estendido 2021)},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:246953635}
}

@article{Bezerra2021PropostaDC,
  title={Proposta de Controle de Espalhamento Espectral Utilizando Aprendizado por Reforço Profundo para Otimizaç{\~a}o do Desempenho de Redes LoRa/LoRaWAN},
  author={C. de S. Bezerra and Ant{\^o}nio Oliveira-Jr and Fl{\'a}vio Henrique Teles Vieira},
  journal={Anais da IX Escola Regional de Inform{\'a}tica de Goi{\'a}s (ERI-GO 2021)},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:245461569}
}

@article{Bezerra2023AprendizagemPR,
  title={Aprendizagem por Reforço Profundo com Redes Convolucionais Aplicada {\`a} Navegaç{\~a}o Aut{\^o}noma de Rob{\^o}s Reais Utilizando Treinamento em Cen{\'a}rio Virtual},
  author={Carlos Daniel Bezerra and Fl{\'a}vio Vieira},
  journal={Anais do XVI Congresso Brasileiro de Intelig{\^e}ncia Computacional},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:267512800}
}

@article{Lima2023AplicaoDM,
  title={Aplicaç{\~a}o do M{\'e}todo de Entropia Cruzada em Aprendizagem por Reforço para Controle de Fator de Espalhamento Espectral em Sistemas Internet das Coisas},
  author={Vittor Gomes Lima and Carlos Daniel Bezerra and Fl{\'a}vio Vieira},
  journal={Anais do XVI Congresso Brasileiro de Intelig{\^e}ncia Computacional},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:267534819}
}

@misc{pendyala2024solvingrealworldoptimizationproblem,
  title={Solving a Real-World Optimization Problem Using Proximal Policy Optimization with Curriculum Learning and Reward Engineering},
  author={Abhijeet Pendyala and Asma Atamna and Tobias Glasmachers},
  year={2024},
  eprint={2404.02577},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2404.02577}
}

@misc{han2018amberadaptivemultibatchexperience,
  title={AMBER: Adaptive Multi-Batch Experience Replay for Continuous Action Control},
  author={Seungyul Han and Youngchul Sung},
  year={2018},
  eprint={1710.04423},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1710.04423}
}

@article{Muller2023MultiAgentPP,
  title={Multi-Agent Proximal Policy Optimization for a Deadlock Capable Transport System in a Simulation-Based Learning Environment},
  author={Marcel M{\"u}ller and Tobias Reggelin and Hartmut Zadek and Lorena S. Reyes-Rubiano},
  journal={2023 Winter Simulation Conference (WSC)},
  year={2023},
  pages={1818-1829},
  url={https://api.semanticscholar.org/CorpusID:267338219}
}

@article{Li2022ResearchOO,
  title={Research on Obstacle Avoidance Strategy of Grid Workspace Based on Deep Reinforcement Learning},
  author={Shuo Li and Jun Zhang and Bin Zheng},
  journal={2022 2nd Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)},
  year={2022},
  pages={11-15},
  url={https://api.semanticscholar.org/CorpusID:250663044}
}

@article{Tiong2022AutonomousVP,
  title={Autonomous Valet Parking with Asynchronous Advantage Actor-Critic Proximal Policy Optimization},
  author={Teckchai Tiong and Ismail Saad and Kenneth Tze Kin Teo and Herwansyah Bin Lago},
  journal={2022 IEEE 12th Annual Computing and Communication Workshop and Conference (CCWC)},
  year={2022},
  pages={0334-0340},
  url={https://api.semanticscholar.org/CorpusID:247231050}
}

@misc{azadeh2024advancesmultiagentreinforcementlearning,
  title={Advances in Multi-agent Reinforcement Learning: Persistent Autonomy and Robot Learning Lab Report 2024}, 
  author={Reza Azadeh},
  year={2024},
  eprint={2412.21088},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2412.21088}
}

@misc{baheri2024synergyoptimaltransporttheory,
  title={The Synergy Between Optimal Transport Theory and Multi-Agent Reinforcement Learning}, 
  author={Ali Baheri and Mykel J. Kochenderfer},
  year={2024},
  eprint={2401.10949},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2401.10949}
}

@inproceedings{Li2023RACEIM,
  title={RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution},
  author={Pengyi Li and Jianye Hao and Hongyao Tang and Yan Zheng and Xian Fu},
  booktitle={International Conference on Machine Learning},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:260872223}
}

@misc{wang2024multipleshipscooperativenavigation,
  title={Multiple Ships Cooperative Navigation and Collision Avoidance using Multi-agent Reinforcement Learning with Communication}, 
  author={Y. Wang and Y. Zhao},
  year={2024},
  eprint={2410.21290},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  url={https://arxiv.org/abs/2410.21290}
}

@article{NiedziolkaDomanski2024AnEM,
  title={An environment model in multi-agent reinforcement learning with decentralized training},
  author={Rafał Niedzi{\'o}łka-Domański and Jarosław Bylina},
  journal={2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS)},
  year={2024},
  pages={661-666},
  url={https://api.semanticscholar.org/CorpusID:273573410}
}

@misc{delafuente2024gametheorymultiagentreinforcement,
  title={Game Theory and Multi-Agent Reinforcement Learning: From Nash Equilibria to Evolutionary Dynamics}, 
  author={Neil De La Fuente and Miquel Noguer i Alonso and Guim Casadellà},
  year={2024},
  eprint={2412.20523},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2412.20523}
}
@article{DeSouzaRibeiro2024AuxlioAD,
  title={Aux{\'i}lio ao diagn{\'o}stico de doenças emocionais e transtornos utilizando t{\'e}cnicas de aprendizado de m{\'a}quina},
  author={Artur De Souza Ribeiro and Wandr{\'e} Nunes de Pinho Veloso},
  journal={Programa de Iniciaç{\~a}o Cient{\'i}fica - PIC/UniCEUB - Relat{\'o}rios de Pesquisa},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:268181246}
}

@article{Brito2023AplicaesDA,
  title={Aplicaç{\~o}es de Aprendizado por Reforço em Manipuladores Rob{\'o}ticos: Uma Revis{\~a}o Sistem{\'a}tica},
  author={Frank Werlly Mendes de Brito and Andr{\'e} Luiz Carvalho Ottoni and Lara Toledo Cordeiro Ottoni},
  journal={Anais do XVI Congresso Brasileiro de Intelig{\^e}ncia Computacional},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:267519766}
}

@article{Felippe2024OUD,
  title={O uso de IA em ambientes de aprendizagem personalizados},
  author={Kellin Rangel Callegari Felippe and Deise Cordeiro de Souza and Herm{\'o}crates Gomes Melo J{\'u}nior and Jonathan Porto Galdino do Carmo and Marcos Antonio Soares de Andrade Filho and Renato Fernandes dos Santos and Rodrigo Rodrigues Pedra and Jocelino Ant{\^o}nio Demuner},
  journal={Caderno Pedag{\'o}gico},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:269631777}
}

@article{Rocha2024SonsPE,
  title={Sons pulmonares e intelig{\^e}ncia artificial: uma scoping review das t{\'e}cnicas de aprendizado de m{\'a}quina aplicadas},
  author={Rodrigo Barbieri Rocha and Roberto Habermann Filho and Lucas dos Santos Batista and Geovana Maria Duarte and Marcos Roberto Torres J{\'u}nior},
  journal={REVISTA DELOS},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:274473157}
}

@article{Dias2023AplicaoDA,
  title={Aplicaç{\~a}o de AutoML em T{\'e}cnicas de Aprendizado de M{\'a}quina para Classificaç{\~a}o de Motoristas},
  author={Francisco {\'E}rbio Dias and Jos{\'e} Maria Pires Menezes Junior},
  journal={Anais do XVI Congresso Brasileiro de Intelig{\^e}ncia Computacional},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:267408732}
}

@article{Geremias2024OUD,
  title={O uso de Game Learning Analytics em Jogos Digitais Educacionais: Um Mapeamento Sistem{\'a}tico da Literatura},
  author={Matheus Soppa Geremias and Taynara Cerigueli Dutra and Eleandro Maschio and Isabela Gasparini},
  journal={Anais do XXXV Simp{\'o}sio Brasileiro de Inform{\'a}tica na Educaç{\~a}o (SBIE 2024)},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:274414399}
}

@misc{sukhbaatar2018learninggoalembeddingsselfplay,
  title={Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement Learning}, 
  author={Sainbayar Sukhbaatar and Emily Denton and Arthur Szlam and Rob Fergus},
  year={2018},
  eprint={1811.09083},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1811.09083}
}

@article{Brando2022MultiagentRL,
  title={Multiagent Reinforcement Learning for Strategic Decision Making and Control in Robotic Soccer Through Self-Play},
  author={Bruno Brand{\~a}o and Telma De Lima and Anderson Soares and Luckeciano Carvalho Melo and Marcos R.O.A. Maximo},
  journal={IEEE Access},
  year={2022},
  volume={10},
  pages={72628-72642},
  url={https://api.semanticscholar.org/CorpusID:250367384}
}

@article{Szemenyei2020LearningTP,
  title={Learning to Play Robot Soccer from Partial Observations},
  author={Marton Szemenyei and Patrik Reizinger},
  journal={2020 23rd International Symposium on Measurement and Control in Robotics (ISMCR)},
  year={2020},
  pages={1-6},
  url={https://api.semanticscholar.org/CorpusID:227219968}
}
@article{Cheng2022AuthenticBoundary,
  title={Authentic Boundary Proximal Policy Optimization},
  author={Yuan Cheng and Liang Huang and Xiaolin Wang},
  journal={IEEE transactions on cybernetics},
  year={2022},
  volume={52},
  number={9},
  pages={9428-9438},
  url={https://doi.org/10.1109/TCYB.2021.3051456}
}
@article{Jia2024ProximalPO,
  title={Proximal Policy Optimization with an Activated Policy Clipping},
  author={Lu Jia and Binglin Su and Du Xu and Yewei Wang},
  journal={2024 International Conference on Energy and Electrical Engineering (EEE)},
  year={2024},
  pages={1-5},
  url={https://api.semanticscholar.org/CorpusID:273377663}
}

@article{Liu2020OverviewOR,
  title={Overview of Reinforcement Learning Based on Value and Policy},
  author={Yunting Liu and Jia-ming Yang and Liang Chen and Ting Guo and Yu Jiang},
  journal={2020 Chinese Control And Decision Conference (CCDC)},
  year={2020},
  pages={598-603},
  url={https://api.semanticscholar.org/CorpusID:221118937}
}

@article{Takada2020ReinforcementLT,
  title={Reinforcement Learning to Create Value and Policy Functions Using Minimax Tree Search in Hex},
  author={Kei Takada and Hiroyuki Iizuka and Masahito Yamamoto},
  journal={IEEE Transactions on Games},
  year={2020},
  volume={12},
  pages={63-73},
  url={https://api.semanticscholar.org/CorpusID:68152112}
}

@article{Kim_2022,
   title={Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value At Risk},
   volume={7},
   ISSN={2377-3774},
   url={http://dx.doi.org/10.1109/LRA.2022.3184793},
   DOI={10.1109/lra.2022.3184793},
   number={3},
   journal={IEEE Robotics and Automation Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Kim, Dohyeong and Oh, Songhwai},
   year={2022},
   month=jul, pages={7644–7651} 
}

@misc{yao2020smixlambdaenhancingcentralizedvalue,
  title={SMIX($\lambda$): Enhancing Centralized Value Functions for Cooperative Multi-Agent Reinforcement Learning}, 
  author={Xinghu Yao and Chao Wen and Yuhui Wang and Xiaoyang Tan},
  year={2020},
  eprint={1911.04094},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/1911.04094}, 
}

@misc{relay_long_horizon,
      title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning}, 
      author={Abhishek Gupta and Vikash Kumar and Corey Lynch and Sergey Levine and Karol Hausman},
      year={2019},
      eprint={1910.11956},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.11956}, 
}

@misc{curriculum_learning_survey,
      title={Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey}, 
      author={Sanmit Narvekar and Bei Peng and Matteo Leonetti and Jivko Sinapov and Matthew E. Taylor and Peter Stone},
      year={2020},
      eprint={2003.04960},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2003.04960}, 
}

@InProceedings{rSoccer,
author="Martins, Felipe B.
and Machado, Mateus G.
and Bassani, Hansenclever F.
and Braga, Pedro H. M.
and Barros, Edna S.",
editor="Alami, Rachid
and Biswas, Joydeep
and Cakmak, Maya
and Obst, Oliver",
title="rSoccer: A Framework for Studying Reinforcement Learning in Small and Very Small Size Robot Soccer",
booktitle="RoboCup 2021: Robot World Cup XXIV",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="165--176",
abstract="Reinforcement learning is an active research area with a vast number of applications in robotics, and the RoboCup competition is an interesting environment for studying and evaluating reinforcement learning methods. A known difficulty in applying reinforcement learning to robotics is the high number of experience samples required, being the use of simulated environments for training the agents followed by transfer learning to real-world (sim-to-real) a viable path. This article introduces an open-source simulator for the IEEE Very Small Size Soccer and the Small Size League optimized for reinforcement learning experiments. We also propose a framework for creating OpenAI Gym environments with a set of benchmarks tasks for evaluating single-agent and multi-agent robot soccer skills. We then demonstrate the learning capabilities of two state-of-the-art reinforcement learning methods as well as their limitations in certain scenarios introduced in this framework. We believe this will make it easier for more teams to compete in these categories using end-to-end reinforcement learning approaches and further develop this research area.",
isbn="978-3-030-98682-7"
}

@misc{framework_pequi_rSoccer,
    title = {Implementação do trabalho  Multiagent Reinforcement Learning for Strategic Decision Making and Control in Robotic Soccer Through Self-Play  },
    year = {2024},
    url = {https://github.com/Pequi-Mecanico-SSL/RL}
}

@misc{robocin,
    title = {Site oficial da RobôCin},
    year = {2025},
    url = {https://www.robocin.com.br/}
}

@misc{pequi_mecanico,
    title = {Site oficial do Pequi Mecânico},
    year = {2025},
    url = {https://www.pequi-mecanico.com.br/inicio}
}
