\chapter{Fundamentação Teórica}
\label{cap:fund}

%% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Aprendizado por Reforço}
\label{sec:rl}

\subsection{Fundamentos do Aprendizado por Reforço}
\label{subsec:rl_fund}

\subsubsection{Definição e conceitos básicos}
\label{subsubsec:rl_conceitos}

\subsubsection{Processo de Decisão de Markov (MDP)}
\label{subsubsec:mdp}

\subsubsection{Funções de valor e política}
\label{subsubsec:valor_politica}

\subsection{Aprendizado por Reforço Profundo}
\label{subsec:deep_rl}

\subsubsection{Redes neurais como aproximadores de função}
\label{subsubsec:redes_neurais}

\subsubsection{Desafios específicos em ambientes visuais complexos}
\label{subsubsec:desafios_visuais}

\subsection{Proximal Policy Optimization (PPO)}
\label{subsec:ppo}

\subsubsection{Motivação e princípios do PPO}
\label{subsubsec:ppo_principios}

\subsubsection{Função objetivo e mecanismo de clipping}
\label{subsubsec:ppo_objetivo}

\subsubsection{Vantagens do PPO em ambientes contínuos e multiagentes}
\label{subsubsec:ppo_vantagens}

%% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Aprendizado por Reforço Multiagente}
\label{sec:marl}

\subsection{Desafios em Ambientes Multiagente}
\label{subsec:desafios_multi}

\subsubsection{Coordenação e competição entre agentes}
\label{subsubsec:coordenacao}

\subsubsection{Não-estacionariedade do ambiente}
\label{subsubsec:nao_estacionariedade}

\subsection{Aplicações em Futebol de Robôs}
\label{subsec:futebol_robos}

\subsubsection{Visão geral da categoria SSL-EL}
\label{subsubsec:ssl_el}

\subsubsection{Desafios específicos do domínio}
\label{subsubsec:desafios_dominio}

%% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Técnicas de Aprendizado Progressivo}
\label{sec:aprendizado_prog}

\subsection{Curriculum Learning}
\label{subsec:curriculum}

\subsubsection{Conceito e motivação}
\label{subsubsec:curriculum_conceito}

\subsubsection{Desenho de currículos para RL}
\label{subsubsec:curriculum_desenho}

\subsubsection{Aplicações em robótica e jogos}
\label{subsubsec:curriculum_aplicacoes}

\subsection{Self-Play}
\label{subsec:self_play}

\subsubsection{Princípios do self-play em RL}
\label{subsubsec:self_play_principios}

\subsubsection{Geração automática de currículos via self-play}
\label{subsubsec:self_play_curriculos}

\subsubsection{Exemplos de sucesso em jogos complexos}
\label{subsubsec:self_play_exemplos}

%% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\section{Integração de Técnicas para Aquisição Progressiva de Habilidades}
\label{sec:integracao}

\subsection{Combinando Curriculum Learning e Self-Play}
\label{subsec:combinacao}

\subsubsection{Sinergias entre as abordagens}
\label{subsubsec:sinergias}

\subsubsection{Desafios na integração}
\label{subsubsec:desafios_integracao}

\subsection{Aplicação ao Futebol de Robôs Multiagente}
\label{subsec:aplicacao_futebol}

\subsubsection{Desenho de currículos para habilidades de futebol}
\label{subsubsec:curriculos_futebol}

\subsubsection{Transição do curriculum para self-play competitivo}
\label{subsubsec:transicao_self_play}

\subsubsection{Potenciais benefícios na aquisição de habilidades complexas}
\label{subsubsec:beneficios_aquisicao}