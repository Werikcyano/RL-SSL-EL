\chapter{Introdução}
\label{cap:intro}

O futebol de robôs representa um domínio desafiador para a aplicação de técnicas de Inteligência Artificial, combinando aspectos complexos de percepção, tomada de decisão e controle em tempo real. Neste contexto, o Aprendizado por Reforço (\textit{Reinforcement Learning} - RL) emergiu como uma abordagem promissora, permitindo que agentes desenvolvam comportamentos sofisticados através da interação direta com o ambiente \cite{sutton}. No entanto, a complexidade inerente ao domínio do futebol de robôs apresenta desafios significativos para o aprendizado efetivo.

O futebol de robôs surgiu como um desafio-problema na RoboCup, uma iniciativa internacional dedicada à promoção da pesquisa em robótica e inteligência artificial. Dentre as várias categorias da competição, a \textit{Small Size League - Entry Level} (SSL-EL) representa uma versão simplificada da liga SSL tradicional, projetada para facilitar a entrada de novas equipes. Na SSL-EL, cada equipe opera até três robôs autônomos em um campo de 5,5m × 4m, sendo um dos robôs designado como goleiro. Os robôs possuem formato cilíndrico padronizado (0,18m de diâmetro por 0,15m de altura) e são identificados por padrões visuais no topo, que permitem sua detecção por um sistema de visão computacional centralizado. A partida é estruturada em dois tempos de 5 minutos, com regras específicas para faltas, penalidades e situações de jogo. Este ambiente controlado oferece um excelente campo de testes para algoritmos de IA, combinando problemas de percepção (através do sistema de visão), planejamento (estratégias de jogo) e ação (controle dos robôs) em um cenário dinâmico multiagente \cite{regras_ssl_el_2024}.

As características específicas da categoria SSL-EL introduzem desafios técnicos particulares que influenciam diretamente o desenvolvimento de soluções baseadas em aprendizado de máquina. O tamanho reduzido do campo (comparado à categoria SSL completa) e o número limitado de robôs (três por equipe) simplificam alguns aspectos, mas também impõem restrições específicas. Por exemplo, as regras severas sobre velocidade máxima dos robôs (1,5m/s) e da bola (3m/s), as limitações nas áreas de atuação, e as penalidades acumulativas exigem que os agentes desenvolvam não apenas habilidades técnicas, mas também observem as regras do jogo durante suas ações. Adicionalmente, a necessidade de especialização dos papéis (goleiro e jogadores de linha) impõe uma dimensão extra de complexidade na coordenação da equipe. Estes fatores tornam a aplicação de \textit{Curriculum Learning} particularmente relevante, pois permite que os agentes primeiro dominem habilidades básicas dentro das restrições das regras, antes de progredirem para comportamentos táticos e estratégicos mais sofisticados.

Um dos obstáculos no desenvolvimento de agentes para futebol de robôs através de RL é a necessidade de aprender múltiplas habilidades interdependentes simultaneamente \cite{ssl_skills}. Os agentes precisam dominar desde capacidades básicas, como navegação e controle da bola \cite{soccer_skills_bipedal_robot}, até comportamentos táticos complexos que envolvem coordenação multiagente \cite{bruno_brandao}. Esta multiplicidade de habilidades, combinada com a natureza contínua do espaço de estados e ações, torna o processo de aprendizagem particularmente desafiador \cite{soccer_skills_bipedal_robot}.

Para endereçar estes desafios, este trabalho propõe a aplicação de \textit{Curriculum Learning} \cite{curriculum} como estratégia para melhorar a eficiência e eficácia do processo de aprendizagem em futebol de robôs. O \textit{Curriculum Learning} permite uma abordagem estruturada ao aprendizado, onde os agentes são expostos a tarefas progressivamente mais complexas, facilitando a aquisição gradual de competências fundamentais. Esta abordagem é especialmente relevante no contexto da categoria \textit{SSL-EL} (\textit{Small Size League - Entry Level}), onde os agentes precisam desenvolver habilidades básicas antes de enfrentar cenários competitivos completos \cite{regras_ssl_el_2024}.

A motivação principal deste trabalho surge da observação de trabalhos anteriores \cite{bruno_brandao}, que demonstrou a viabilidade do uso de Aprendizado por Reforço no contexto de futebol de robôs através do algoritmo \textit{Proximal Policy Optimization} (PPO) em uma abordagem multi-agente com política compartilhada. No entanto, aplicar diretamente métodos de RL ao problema completo do futebol de robôs, sem uma estrutura progressiva de aprendizado, frequentemente resulta em um processo ineficiente e instável. Inspirado pela forma como jogos populares como \textit{FIFA} e \textit{Rocket League} introduzem novos jogadores através de centros de treinamento antes de permitir a competição direta, este trabalho propõe uma abordagem baseada em \textit{Curriculum Learning} para estruturar o processo de aprendizagem em etapas progressivas. Esta estratégia permite que os agentes desenvolvam primeiro habilidades fundamentais antes de enfrentarem cenários mais complexos, similar ao processo natural de desenvolvimento de habilidades em jogadores humanos \cite{relay_long_horizon}.

O objetivo geral deste trabalho é desenvolver e avaliar uma metodologia baseada em \textit{Curriculum Learning} para melhorar o processo de aprendizagem de agentes em futebol de robôs. Especificamente, busca-se:

1. Desenvolver uma estrutura de \textit{curriculum} que decomponha o aprendizado em estágios progressivos, começando com habilidades fundamentais como chute básico e progredindo até comportamentos mais complexos;

2. Implementar um sistema de transição adaptativo entre níveis do \textit{curriculum}, garantindo que os agentes desenvolvam uma base sólida antes de progredir para tarefas mais desafiadoras;

3. Avaliar comparativamente o desempenho de agentes treinados com e sem \textit{Curriculum Learning}, considerando métricas como eficiência no aprendizado e qualidade final do comportamento aprendido.

Este trabalho está estruturado de forma a apresentar progressivamente os conceitos, metodologias e resultados da pesquisa. No Capítulo \ref{cap:fund}, são aprofundados os conceitos teóricos essenciais para a compreensão do trabalho, abordando Aprendizado por Reforço, o algoritmo PPO, \textit{Multi-agent RL}, \textit{Self-play}, \textit{Curriculum Learning} e aspectos específicos do futebol de robôs. O Capítulo \ref{cap:metodologia} detalha o ambiente de simulação utilizado, a arquitetura do sistema proposto e a implementação do \textit{Curriculum Learning}, incluindo seus estágios progressivos e mecanismos de transição.

No Capítulo \ref{cap:resultados}, são apresentados os experimentos realizados, incluindo análises comparativas entre diferentes abordagens de treinamento e os resultados dos torneios, evidenciando a eficácia da metodologia proposta. Por fim, o Capítulo \ref{cap:conclusao} sintetiza as principais descobertas e contribuições do trabalho, discutindo suas implicações para o campo do aprendizado por reforço em ambientes multiagentes, apresentando limitações identificadas e sugerindo direções para trabalhos futuros. O trabalho inclui ainda uma subseção dedicada à reprodutibilidade dos experimentos, sendo complementado por gráficos, tabelas e referências a vídeos demonstrativos disponíveis online.

As principais contribuições esperadas deste trabalho incluem uma metodologia estruturada para aplicação de \textit{Curriculum Learning} em futebol de robôs, um \textit{framework} adaptativo para progressão entre níveis de complexidade e evidências empíricas sobre a efetividade do \textit{Curriculum Learning} em melhorar o processo de aprendizagem em ambientes complexos multiagente. Este trabalho utiliza como base a implementação \cite{framework_pequi_rSoccer} do trabalho \textit{Multiagent Reinforcement Learning for Strategic Decision Making and Control in Robotic Soccer Through Self-Play} \cite{bruno_brandao} realizada pela equipe Pequi Mecânico \cite{pequi_mecanico}, que por sua vez foi desenvolvida utilizando o \textit{framework} RSoccer \cite{rSoccer} da equipe RobôCIn \cite{robocin}. O código fonte completo desta solução está disponível em \url{https://github.com/Werikcyano/RL-SSL-EL}.
